{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38e60c3f",
        "outputId": "ab5abacb-cd19-4c97-a752-b148e883bde6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboard_logger\n",
            "  Downloading tensorboard_logger-0.1.0-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (8.4.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (3.20.3)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (1.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboard_logger) (1.22.4)\n",
            "Installing collected packages: tensorboard_logger\n",
            "Successfully installed tensorboard_logger-0.1.0\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import torch\n",
        "import argparse\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "from math import log10\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "# from data_utils import DatasetFromH5_SFSR\n",
        "# from model import Net_SRCNN\n",
        "!pip install tensorboard_logger\n",
        "from tensorboard_logger import configure, log_value\n",
        "\n",
        "# from data_utils import DatasetFromH5_MFSR\n",
        "# from model import Net_VSRNet\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "id": "38e60c3f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b2fd3a7"
      },
      "source": [
        "## ESRGAN"
      ],
      "id": "9b2fd3a7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c765661"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "import h5py\n",
        "\n",
        "class DatasetFromH5_MFSR(Dataset):\n",
        "    def __init__(self, image_dataset_dir, target_dataset_dir, upscale_factor, input_transform=None, target_transform=None):\n",
        "        super(DatasetFromH5_MFSR, self).__init__()\n",
        "        \n",
        "        image_h5_file = h5py.File(image_dataset_dir, 'r')\n",
        "        target_h5_file = h5py.File(target_dataset_dir, 'r')\n",
        "        image_dataset = image_h5_file['data']\n",
        "        target_dataset = target_h5_file['data']\n",
        "        \n",
        "        self.image_datasets = image_dataset\n",
        "        self.target_datasets = target_dataset\n",
        "        self.total_count = image_dataset.shape[0]\n",
        "        \n",
        "        self.input_transform = input_transform\n",
        "        self.target_transform = target_transform\n",
        "        \n",
        "    def __getitem__(self, index):        \n",
        "        image = self.image_datasets[index, :, :, :]\n",
        "        target = self.target_datasets[index, [2], :, :]\n",
        "        \n",
        "        image  = image.astype(np.float32)\n",
        "        target = target.astype(np.float32)\n",
        "        \n",
        "        #   Notice that image is the bicubic upscaled LR image patch, in float format, in range [0, 1]\n",
        "#        image = image / 255.0 \n",
        "        #   Notice that target is the HR image patch, in uint8 format, in range [0, 255]\n",
        "        target = target / 255.0\n",
        "        \n",
        "        image =  torch.from_numpy(image)\n",
        "        target = torch.from_numpy(target)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_count"
      ],
      "id": "3c765661"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFf6x0DDXRYo"
      },
      "outputs": [],
      "source": [
        "data_dir = \"./data\"\n",
        "\n",
        "downloads_dir = data_dir + '/downloads'\n",
        "datasets_dir = data_dir + '/datasets'\n",
        "models_dir = data_dir + '/models'\n",
        "pretrained_models = data_dir + '/pretrained_models'\n",
        "\n",
        "os.makedirs(downloads_dir, exist_ok=True)\n",
        "os.makedirs(datasets_dir, exist_ok=True)\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "os.makedirs(pretrained_models, exist_ok=True)\n",
        "\n",
        "uf4_train_dir = datasets_dir + '/uf4_train'\n",
        "uf4_val_dir = datasets_dir + '/uf4_val'\n",
        "\n",
        "srrnet_train_lr = uf4_train_dir + '/srrnet_train_lr.h5'\n",
        "srrnet_train_hr = uf4_train_dir + '/srrnet_train_hr.h5'\n",
        "\n",
        "srrnet_val_lr = uf4_val_dir + '/srrnet_val_lr.h5'\n",
        "srrnet_val_hr = uf4_val_dir + '/srrnet_val_hr.h5'\n",
        "\n",
        "!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AACDZmHK7d2JQi0ADaoliM04a/uf_4/train/Data_CDVL_LR_Bic_MC_uf_4_ps_72_fn_5_tpn_225000.h5 -O srrnet_train_lr\n",
        "!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AACmrvoqkXXnZTXUFsWvNDCsa/uf_4/train/Data_CDVL_HR_uf_4_ps_72_fn_5_tpn_225000.h5 -O srrnet_train_hr\n",
        "\n",
        "!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AADJnJmRvFxmf7sxEk5G0Uuma/uf_4/val/Data_CDVL_LR_Bic_MC_uf_4_ps_72_fn_5_tpn_45000.h5 -O srrnet_val_lr\n",
        "!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAChoVG4fLqdpsmSuq9wrEvFa/uf_4/val/Data_CDVL_HR_uf_4_ps_72_fn_5_tpn_45000.h5 -O srrnet_val_hr\n",
        "\n"
      ],
      "id": "zFf6x0DDXRYo"
    },
    {
      "cell_type": "code",
      "source": [
        "#import pickle\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tZfw7GgSSZSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b52752-dcc1-4dc4-a6b8-d2ce067f5c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "id": "tZfw7GgSSZSb"
    },
    {
      "cell_type": "code",
      "source": [
        "#with open('/content/drive/MyDrive/train_subset_12800.pkl', 'rb') as f:\n",
        "   # subset_train = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "yxNOa8_gO39f"
      },
      "execution_count": null,
      "outputs": [],
      "id": "yxNOa8_gO39f"
    },
    {
      "cell_type": "code",
      "source": [
        "#with open('/content/drive/MyDrive/val_subset_12800.pkl', 'rb') as f:\n",
        "   # subset_val = pickle.load(f)"
      ],
      "metadata": {
        "id": "pscx__FvTJkp"
      },
      "execution_count": null,
      "outputs": [],
      "id": "pscx__FvTJkp"
    },
    {
      "cell_type": "code",
      "source": [
        "subset_val.image_datasets = subset_val.image_datasets[0:256,:,:,:]\n",
        "subset_val.target_datasets = subset_val.target_datasets[0:256,:,:,:]\n",
        "\n",
        "subset_train.image_datasets = subset_train.image_datasets[0:256,:,:,:]\n",
        "subset_train.target_datasets = subset_train.target_datasets[0:256,:,:,:]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aEWfuZu_zUqG"
      },
      "id": "aEWfuZu_zUqG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upscale_factor = 4\n",
        "threads = 1\n",
        "batchSize = 64 #256\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=subset_train, num_workers=threads, batch_size=batchSize, shuffle=False)\n",
        "val_loader = DataLoader(dataset=subset_val, num_workers=threads, batch_size=batchSize, shuffle=False)"
      ],
      "metadata": {
        "id": "A_8YXp3WnXrF"
      },
      "id": "A_8YXp3WnXrF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the pretrained SRCNN"
      ],
      "metadata": {
        "id": "z9WRd1A80rWD"
      },
      "id": "z9WRd1A80rWD"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def make_layer(block, n_layers):\n",
        "    layers = []\n",
        "    for _ in range(n_layers):\n",
        "        layers.append(block())\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class ResidualDenseBlock_5C(nn.Module):\n",
        "    def __init__(self, nf=64, gc=32, bias=True):\n",
        "        super(ResidualDenseBlock_5C, self).__init__()\n",
        "        # gc: growth channel, i.e. intermediate channels\n",
        "        self.conv1 = nn.Conv2d(nf, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv2 = nn.Conv2d(nf + gc, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv3 = nn.Conv2d(nf + 2 * gc, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv4 = nn.Conv2d(nf + 3 * gc, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv5 = nn.Conv2d(nf + 4 * gc, nf, 3, 1, 1, bias=bias)\n",
        "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "        # initialization\n",
        "        # mutil.initialize_weights([self.conv1, self.conv2, self.conv3, self.conv4, self.conv5], 0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.lrelu(self.conv1(x))\n",
        "        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\n",
        "        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\n",
        "        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\n",
        "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
        "        return x5 * 0.2 + x\n",
        "\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "    '''Residual in Residual Dense Block'''\n",
        "\n",
        "    def __init__(self, nf, gc=32):\n",
        "        super(RRDB, self).__init__()\n",
        "        self.RDB1 = ResidualDenseBlock_5C(nf, gc)\n",
        "        self.RDB2 = ResidualDenseBlock_5C(nf, gc)\n",
        "        self.RDB3 = ResidualDenseBlock_5C(nf, gc)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.RDB1(x)\n",
        "        out = self.RDB2(out)\n",
        "        out = self.RDB3(out)\n",
        "        return out * 0.2 + x\n",
        "\n",
        "\n",
        "class RRDBNet(nn.Module):\n",
        "    def __init__(self, in_nc, out_nc, nf, nb, gc=32):\n",
        "        super(RRDBNet, self).__init__()\n",
        "        RRDB_block_f = functools.partial(RRDB, nf=nf, gc=gc)\n",
        "\n",
        "        self.conv_first = nn.Conv2d(in_nc, nf, 3, 1, 1, bias=True)\n",
        "        self.RRDB_trunk = make_layer(RRDB_block_f, nb)\n",
        "        self.trunk_conv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        #### upsampling\n",
        "        self.upconv1 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.upconv2 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.HRconv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.conv_last = nn.Conv2d(nf, out_nc, 3, 1, 1, bias=True)\n",
        "\n",
        "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        fea = self.conv_first(x)\n",
        "        trunk = self.trunk_conv(self.RRDB_trunk(fea))\n",
        "        fea = fea + trunk\n",
        "\n",
        "        fea = self.lrelu(self.upconv1(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
        "        fea = self.lrelu(self.upconv2(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
        "        out = self.conv_last(self.lrelu(self.HRconv(fea)))\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "BpSU0Rp2hjsG"
      },
      "id": "BpSU0Rp2hjsG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yimvkyZxjSYy"
      },
      "id": "yimvkyZxjSYy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d0cWmi_-odg2"
      },
      "id": "d0cWmi_-odg2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "QfrteW-Dodbc"
      },
      "id": "QfrteW-Dodbc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_net = torch.load('RRDB_ESRGAN_x4.pth')"
      ],
      "metadata": {
        "id": "eSu1uFpxjSU3"
      },
      "id": "eSu1uFpxjSU3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'RRDB_ESRGAN_x4.pth'\n",
        "\n",
        "pretrained_net = torch.load('RRDB_ESRGAN_x4.pth')\n",
        "\n",
        "\n",
        "crt_model = RRDBNet(3, 3, 64, 23, gc=32)\n",
        "crt_net = crt_model.state_dict()\n",
        "\n",
        "load_net_clean = {}\n",
        "\n",
        "for k, v in pretrained_net.items():\n",
        "    if k.startswith('module.'):\n",
        "        load_net_clean[k[7:]] = v\n",
        "    else:\n",
        "        load_net_clean[k] = v\n",
        "\n",
        "pretrained_net = load_net_clean\n"
      ],
      "metadata": {
        "id": "naQckfrJjSN8"
      },
      "id": "naQckfrJjSN8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'RRDB_ESRGAN_x4.pth'\n",
        "\n",
        "\n",
        "srcnn = RRDBNet(3, 3, 64, 23, gc=32)\n",
        "\n",
        "state_dict = srcnn.state_dict()\n",
        "for n, p in torch.load(path, map_location=lambda storage, loc: storage).items():\n",
        "    if n in state_dict.keys():\n",
        "        state_dict[n].copy_(p)\n",
        "    else:\n",
        "        raise KeyError(n)\n",
        "\n",
        "torch.save(srcnn, path)"
      ],
      "metadata": {
        "id": "SA4-0M4NtYtu"
      },
      "id": "SA4-0M4NtYtu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RRDBNet_video(nn.Module):\n",
        "    def __init__(self, in_nc, out_nc, nf, nb, esrgan, gc=32):\n",
        "        super(RRDBNet_video, self).__init__()\n",
        "        RRDB_block_f = functools.partial(RRDB, nf=nf, gc=gc)\n",
        "        \n",
        "        self.conv_first_0 = nn.Conv2d(in_nc, nf, 3, 1, 1, bias=True)\n",
        "        self.conv_first_1 = nn.Conv2d(in_nc, nf, 3, 1, 1, bias=True)\n",
        "        self.conv_first_2 = nn.Conv2d(in_nc, nf, 3, 1, 1, bias=True)\n",
        "\n",
        "        #self.RRDB_trunk = make_layer(RRDB_block_f, nb)\n",
        "        self.trunk_conv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        \n",
        "        #### upsampling\n",
        "        self.upconv1 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.upconv2 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.HRconv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.conv_last = nn.Conv2d(nf, out_nc, 3, 1, 1, bias=True)\n",
        "\n",
        "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "        self.esrgan = esrgan \n",
        "        \n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        h10 = x[:,[0],:,:].repeat(1,3,1,1)\n",
        "        h11 = x[:,[1],:,:].repeat(1,3,1,1)\n",
        "        h12 = x[:,[2],:,:].repeat(1,3,1,1)\n",
        "        h13 = x[:,[3],:,:].repeat(1,3,1,1)\n",
        "        h14 = x[:,[4],:,:].repeat(1,3,1,1)\n",
        "\n",
        "        \n",
        "        h10 = self.conv_first_0(h10)\n",
        "        h11 = self.conv_first_1(h11)\n",
        "        h12 = self.conv_first_2(h12)\n",
        "        h13 = self.conv_first_1(h13)\n",
        "        h14 = self.conv_first_0(h14) \n",
        "\n",
        "        #fea = self.conv_first(x)\n",
        "        x = F.relu(torch.cat((h10, h11, h12, h13, h14), 1))\n",
        "        #print(x.shape)\n",
        "        trunk = self.trunk_conv(x) #(self.RRDB_trunk(x))\n",
        "        fea = h12 + trunk\n",
        "        \n",
        "        fea = self.lrelu(self.upconv1(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
        "        fea = self.lrelu(self.upconv2(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
        "        out = self.conv_last(self.lrelu(self.HRconv(fea)))\n",
        "        #print(out.shape)  \n",
        "        out = F.interpolate(out, size=(72, 72), mode='bilinear', align_corners=True)\n",
        "        out = out[:,[1],:,:]\n",
        "        return out\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \n",
        "        esrgan = torch.load(self.esrgan, map_location=lambda storage, loc: storage) # forcing to load to CPU\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.conv_first_0.weight.data = (esrgan.conv_first.weight.data).clone()\n",
        "        self.conv_first_1.weight.data = (esrgan.conv_first.weight.data).clone()\n",
        "        self.conv_first_2.weight.data = (esrgan.conv_first.weight.data).clone()\n",
        "        \n",
        "        self.conv_first_0.bias.data = (esrgan.conv_first.bias.data).clone()\n",
        "        self.conv_first_1.bias.data = (esrgan.conv_first.bias.data).clone()\n",
        "        self.conv_first_2.bias.data = (esrgan.conv_first.bias.data).clone()\n",
        "        \n",
        "        #self.RRDB_trunk = make_layer(RRDB_block_f, nb)\n",
        "        self.trunk_conv.bias.data = (esrgan.trunk_conv.bias.data).clone()  # Modify!\n",
        "        self.trunk_conv.weight.data = torch.cat((esrgan.trunk_conv.weight.data,\n",
        "                                                 esrgan.trunk_conv.weight.data,\n",
        "                                                 esrgan.trunk_conv.weight.data,\n",
        "                                                 esrgan.trunk_conv.weight.data,\n",
        "                                                 esrgan.trunk_conv.weight.data),1\n",
        "                                                 ).clone()/5.0         \n",
        "\n",
        "        self.upconv1.bias.data = (esrgan.upconv1.bias.data).clone()  \n",
        "        self.upconv1.weight.data = (esrgan.upconv1.weight.data).clone() \n",
        "\n",
        "        self.upconv2.bias.data = (esrgan.upconv2.bias.data).clone()  \n",
        "        self.upconv2.weight.data = (esrgan.upconv2.weight.data).clone() \n",
        "        \n",
        "        self.HRconv.bias.data = (esrgan.HRconv.bias.data).clone()  \n",
        "        self.HRconv.weight.data = (esrgan.HRconv.weight.data).clone() \n",
        "\n",
        "        self.conv_last.bias.data = (esrgan.conv_last.bias.data).clone()  \n",
        "        self.conv_last.weight.data = (esrgan.conv_last.weight.data).clone() \n",
        "\n",
        "model = RRDBNet_video(3, 3, 64, 23, esrgan = path)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()"
      ],
      "metadata": {
        "id": "xpnfpjqDhjpm"
      },
      "id": "xpnfpjqDhjpm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nEpochs = 4\n",
        "lr = 0.005\n",
        "\n",
        "val(0)\n",
        "checkpoint(0)\n",
        "for epoch in range(1, nEpochs + 1):\n",
        "    train(epoch)\n",
        "    val(epoch)\n",
        "    checkpoint(epoch)"
      ],
      "metadata": {
        "id": "1N5PZq1hhjnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c489191-0ff5-436e-81fd-416b1516c652"
      },
      "id": "1N5PZq1hhjnZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===> Epoch 0 Validation CDVL: Avg. Loss: 0.0016, Avg.PSNR:  29.5735 dB, Time: 8.0910\n",
            "Checkpoint saved to epochs_VSRNet/model_epoch_0.pth\n",
            "===> Epoch 1 Complete: lr: 0.0001, Avg. Loss: 0.0000, Avg.PSNR:  0.0252 dB, Time: 3.3703\n",
            "===> Epoch 1 Validation CDVL: Avg. Loss: 0.0010, Avg.PSNR:  31.2599 dB, Time: 1.6148\n",
            "===> Epoch 2 Complete: lr: 1.0000000000000003e-05, Avg. Loss: 0.0000, Avg.PSNR:  0.0263 dB, Time: 2.3980\n",
            "===> Epoch 2 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  34.3938 dB, Time: 1.5874\n",
            "===> Epoch 3 Complete: lr: 1.0000000000000002e-06, Avg. Loss: 0.0000, Avg.PSNR:  0.0273 dB, Time: 2.4134\n",
            "===> Epoch 3 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  35.0972 dB, Time: 1.5931\n",
            "===> Epoch 4 Complete: lr: 1.0000000000000002e-07, Avg. Loss: 0.0000, Avg.PSNR:  0.0274 dB, Time: 2.4413\n",
            "===> Epoch 4 Validation CDVL: Avg. Loss: 0.0006, Avg.PSNR:  35.1694 dB, Time: 1.6272\n",
            "Checkpoint saved to epochs_VSRNet/model_epoch_4.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4UF5VWRorxT"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ],
      "id": "Z4UF5VWRorxT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohZ9o5FTorxX"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "optimizer = optim.Adam([{'params': model.conv_first_0.parameters()},\n",
        "                        {'params': model.conv_first_1.parameters()},\n",
        "                        {'params': model.conv_first_2.parameters()},\n",
        "                        {'params': model.trunk_conv.parameters()},\n",
        "                        {'params': model.upconv1.parameters()},\n",
        "                        {'params': model.upconv2.parameters()},\n",
        "                        {'params': model.HRconv.parameters()},\n",
        "                        {'params': model.conv_last.parameters(), 'lr': lr/10.0}\n",
        "                        ], lr=lr)"
      ],
      "id": "ohZ9o5FTorxX"
    },
    {
      "cell_type": "code",
      "source": [
        "configure(\"tensorBoardRuns/VSRNet-relu-mid-fusion-pretrain-sym-x4-batch-128-CDVL-225000x5x72x72-wd\")"
      ],
      "metadata": {
        "id": "TP9NYBIvorxY"
      },
      "execution_count": null,
      "outputs": [],
      "id": "TP9NYBIvorxY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Mofp8QworxY"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(epoch):\n",
        "    lr = 0.001\n",
        "    epoch_loss = 0\n",
        "    epoch_psnr = 0\n",
        "    start = time.time()\n",
        "    #   Step up learning rate decay\n",
        "    #   The network have 3 layers\n",
        "    lr = lr * (0.1 ** (epoch // (nEpochs // 4)))\n",
        "    \n",
        "    optimizer.param_groups[0]['lr'] = lr\n",
        "    optimizer.param_groups[1]['lr'] = lr\n",
        "    optimizer.param_groups[2]['lr'] = lr\n",
        "    optimizer.param_groups[3]['lr'] = lr\n",
        "    optimizer.param_groups[4]['lr'] = lr/10.0\n",
        "    \n",
        "\n",
        "    n = 0\n",
        "    for iteration, batch in enumerate(train_loader, 1):\n",
        "        if n >= 3:\n",
        "          break \n",
        "        n = n+1\n",
        "        image, target = Variable(batch[0]), Variable(batch[1])\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(image), target)\n",
        "        psnr = 10 * log10(1 / loss.data.item())\n",
        "        epoch_loss += loss.data.item()\n",
        "        epoch_psnr += psnr\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    end = time.time()\n",
        "    print(\"===> Epoch {} Complete: lr: {}, Avg. Loss: {:.4f}, Avg.PSNR:  {:.4f} dB, Time: {:.4f}\".format(epoch, lr, epoch_loss / len(train_loader), epoch_psnr / len(train_loader), (end-start)))\n",
        "    \n",
        "    log_value('train_loss', epoch_loss / len(train_loader), epoch)\n",
        "    log_value('train_psnr', epoch_psnr / len(train_loader), epoch)"
      ],
      "id": "4Mofp8QworxY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1z5UsA5orxY"
      },
      "outputs": [],
      "source": [
        "def val(epoch):\n",
        "    #   Validation on CDVL val set\n",
        "    lr = 0.001\n",
        "    avg_psnr = 0\n",
        "    avg_mse = 0\n",
        "    frame_count = 0\n",
        "    start = time.time()\n",
        "    n = 0\n",
        "    for batch in val_loader:\n",
        "        if n >= 3:\n",
        "          break \n",
        "        n = n+1\n",
        "        image, target = Variable(batch[0]), Variable(batch[1])\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "        prediction = model(image)\n",
        "\n",
        "        for i in range(0, image.shape[0]):\n",
        "            mse = criterion(prediction[i], target[i])\n",
        "            psnr = 10 * log10(1 / mse.data.item())\n",
        "            avg_psnr += psnr\n",
        "            avg_mse  += mse.data.item()\n",
        "            frame_count += 1\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"===> Epoch {} Validation CDVL: Avg. Loss: {:.4f}, Avg.PSNR:  {:.4f} dB, Time: {:.4f}\".format(epoch, avg_mse / frame_count, avg_psnr / frame_count, (end-start)))\n",
        "\n",
        "    log_value('val_loss', avg_mse / frame_count, epoch)\n",
        "    log_value('val_psnr', avg_psnr / frame_count, epoch)"
      ],
      "id": "d1z5UsA5orxY"
    },
    {
      "cell_type": "code",
      "source": [
        "def checkpoint(epoch):\n",
        "    if epoch%4 == 0:\n",
        "        if not os.path.exists(\"epochs_VSRNet\"):\n",
        "            os.makedirs(\"epochs_VSRNet\")\n",
        "        model_out_path = \"epochs_VSRNet/\" + \"model_epoch_{}.pth\".format(epoch)\n",
        "        torch.save(model, model_out_path)\n",
        "        print(\"Checkpoint saved to {}\".format(model_out_path))"
      ],
      "metadata": {
        "id": "w_QMBnsQ6eio"
      },
      "id": "w_QMBnsQ6eio",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nEpochs = 2\n",
        "lr = 0.001\n",
        "\n",
        "val(0)\n",
        "checkpoint(0)\n",
        "for epoch in range(1, nEpochs + 1):\n",
        "    train(epoch)\n",
        "    val(epoch)\n",
        "    checkpoint(epoch)"
      ],
      "metadata": {
        "id": "sc7jNN0PhjlD"
      },
      "id": "sc7jNN0PhjlD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eRhtmit5hjij"
      },
      "id": "eRhtmit5hjij",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zx9PdhmBhjgG"
      },
      "id": "Zx9PdhmBhjgG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vy2sfObchjYH"
      },
      "id": "vy2sfObchjYH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's test with a video!"
      ],
      "metadata": {
        "id": "LykHAvh-uy4J"
      },
      "id": "LykHAvh-uy4J"
    },
    {
      "cell_type": "code",
      "source": [
        "uf4_test_dir = datasets_dir + '/uf4_test'\n",
        "\n",
        "vsrnet_test_lr = uf4_test_dir + '/vsrnet_test_lr.h5'\n",
        "vsrnet_test_hr = uf4_test_dir + '/vsrnet_test_hr.h5'\n",
        "\n",
        "!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAADzBQ7iA492oQ26ag67ZsKa/uf_4/test/LR_Bic_MC/scene_30.h5 -O vsrnet_test_lr\n",
        "!wget https://www.dropbox.com/sh/1jz9zeer9wxetx2/AADSka3PgSR5EuCt9ByugfY6a/uf_4/test/HR/scene_30.h5 -O vsrnet_test_hr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKIjgWgjuyT2",
        "outputId": "f142fe91-3e88-4b1c-de4c-d6c9ab99c7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-07 20:14:54--  https://www.dropbox.com/sh/1jz9zeer9wxetx2/AAADzBQ7iA492oQ26ag67ZsKa/uf_4/test/LR_Bic_MC/scene_30.h5\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /sh/raw/1jz9zeer9wxetx2/AAADzBQ7iA492oQ26ag67ZsKa/uf_4/test/LR_Bic_MC/scene_30.h5 [following]\n",
            "--2023-05-07 20:14:54--  https://www.dropbox.com/sh/raw/1jz9zeer9wxetx2/AAADzBQ7iA492oQ26ag67ZsKa/uf_4/test/LR_Bic_MC/scene_30.h5\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucfb90e0bc5f994783b10cd5a537.dl.dropboxusercontent.com/cd/0/inline/B7mG7htFWiqRZrfWwijhSTkoLLzoY2WNv-5KtuIo-U982Mw_DOwm4X2RnBVaSN1C9ngt47S2mfVBOLsl2Y48x3fMPUw0yMoAtj0z_MQ7oMwa1pmjOpwVYAEJcH5nxVgbGbhpvSKOtcjELOJRy-l0W-cty5D5tRm1BJa51agx826X9Q/file# [following]\n",
            "--2023-05-07 20:14:55--  https://ucfb90e0bc5f994783b10cd5a537.dl.dropboxusercontent.com/cd/0/inline/B7mG7htFWiqRZrfWwijhSTkoLLzoY2WNv-5KtuIo-U982Mw_DOwm4X2RnBVaSN1C9ngt47S2mfVBOLsl2Y48x3fMPUw0yMoAtj0z_MQ7oMwa1pmjOpwVYAEJcH5nxVgbGbhpvSKOtcjELOJRy-l0W-cty5D5tRm1BJa51agx826X9Q/file\n",
            "Resolving ucfb90e0bc5f994783b10cd5a537.dl.dropboxusercontent.com (ucfb90e0bc5f994783b10cd5a537.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to ucfb90e0bc5f994783b10cd5a537.dl.dropboxusercontent.com (ucfb90e0bc5f994783b10cd5a537.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B7nwwd2vXvVtamGA8LTA90FkGs7Lvo9TKw6m2xaT8zZjzs59RXzRt5Ip_KbmYIICp2-Wnqfj7T4AbeuPF4t0JV6R1gXNft2HKzaPIrIvYKSPH0OA7XNrKmlrWL8cWX-jO6hCMFMiER5OnjruqHQi-lKEmvHbggUZIBYv3h6J3w7bLbHEYndOGELnfbXoUMhQHfUY9KdDPWwrt1_OE_6t9BrfrJjP33gGDxq4X2k3ihNEE6O3uiyK5GlOyECOMUYxk1DeMUfLLvw5gekQaGc55mmr1lJopT1tpfLmHIkZVtSwePaVVtMX0MeDmH9vVOjtNzQKO-48Yvpy-XakHGffH_5h5QYIw-Kv8a7EscYCFhsKifOukFU66z79kL5RuB9sbRxNwh-O5kL1cD7Ga9DsjObMChhLUVvXL1MDm7eEmoSlVg/file [following]\n",
            "--2023-05-07 20:14:55--  https://ucfb90e0bc5f994783b10cd5a537.dl.dropboxusercontent.com/cd/0/inline2/B7nwwd2vXvVtamGA8LTA90FkGs7Lvo9TKw6m2xaT8zZjzs59RXzRt5Ip_KbmYIICp2-Wnqfj7T4AbeuPF4t0JV6R1gXNft2HKzaPIrIvYKSPH0OA7XNrKmlrWL8cWX-jO6hCMFMiER5OnjruqHQi-lKEmvHbggUZIBYv3h6J3w7bLbHEYndOGELnfbXoUMhQHfUY9KdDPWwrt1_OE_6t9BrfrJjP33gGDxq4X2k3ihNEE6O3uiyK5GlOyECOMUYxk1DeMUfLLvw5gekQaGc55mmr1lJopT1tpfLmHIkZVtSwePaVVtMX0MeDmH9vVOjtNzQKO-48Yvpy-XakHGffH_5h5QYIw-Kv8a7EscYCFhsKifOukFU66z79kL5RuB9sbRxNwh-O5kL1cD7Ga9DsjObMChhLUVvXL1MDm7eEmoSlVg/file\n",
            "Reusing existing connection to ucfb90e0bc5f994783b10cd5a537.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 580613056 (554M) [application/octet-stream]\n",
            "Saving to: ‘vsrnet_test_lr’\n",
            "\n",
            "vsrnet_test_lr      100%[===================>] 553.71M   167MB/s    in 3.3s    \n",
            "\n",
            "2023-05-07 20:14:59 (167 MB/s) - ‘vsrnet_test_lr’ saved [580613056/580613056]\n",
            "\n",
            "--2023-05-07 20:14:59--  https://www.dropbox.com/sh/1jz9zeer9wxetx2/AADSka3PgSR5EuCt9ByugfY6a/uf_4/test/HR/scene_30.h5\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.7.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.7.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /sh/raw/1jz9zeer9wxetx2/AADSka3PgSR5EuCt9ByugfY6a/uf_4/test/HR/scene_30.h5 [following]\n",
            "--2023-05-07 20:14:59--  https://www.dropbox.com/sh/raw/1jz9zeer9wxetx2/AADSka3PgSR5EuCt9ByugfY6a/uf_4/test/HR/scene_30.h5\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc98ed90ec8f6cdf3fa92ddc2c5d.dl.dropboxusercontent.com/cd/0/inline/B7kzAFPwEuY9fdkgALXzVYHbldRlQx2XwqbkEqVNjfLR1wz5OuR2NiwH8Zq1wCyZwREKCChigEA1kb0UEek6ZlT9G1yP89oxbjd5u5Nd9nhLNBIetJDQ_bT22yAItVIDs77Sgkb4kI_o2Y48h9qGrxbXZliYr7Ajb56l8h7bxTBxoA/file# [following]\n",
            "--2023-05-07 20:15:00--  https://uc98ed90ec8f6cdf3fa92ddc2c5d.dl.dropboxusercontent.com/cd/0/inline/B7kzAFPwEuY9fdkgALXzVYHbldRlQx2XwqbkEqVNjfLR1wz5OuR2NiwH8Zq1wCyZwREKCChigEA1kb0UEek6ZlT9G1yP89oxbjd5u5Nd9nhLNBIetJDQ_bT22yAItVIDs77Sgkb4kI_o2Y48h9qGrxbXZliYr7Ajb56l8h7bxTBxoA/file\n",
            "Resolving uc98ed90ec8f6cdf3fa92ddc2c5d.dl.dropboxusercontent.com (uc98ed90ec8f6cdf3fa92ddc2c5d.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uc98ed90ec8f6cdf3fa92ddc2c5d.dl.dropboxusercontent.com (uc98ed90ec8f6cdf3fa92ddc2c5d.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29035456 (28M) [text/plain]\n",
            "Saving to: ‘vsrnet_test_hr’\n",
            "\n",
            "vsrnet_test_hr      100%[===================>]  27.69M  97.0MB/s    in 0.3s    \n",
            "\n",
            "2023-05-07 20:15:01 (97.0 MB/s) - ‘vsrnet_test_hr’ saved [29035456/29035456]\n",
            "\n"
          ]
        }
      ],
      "id": "mKIjgWgjuyT2"
    },
    {
      "cell_type": "code",
      "source": [
        "path_LR_Bic_MC = './vsrnet_test_hr'\n",
        "path_HR = './vsrnet_test_hr'\n",
        "videos_h5_name = ['scene_50.h5']\n",
        "videos_h5_name.sort()"
      ],
      "metadata": {
        "id": "O3oQP1rrvc3z"
      },
      "execution_count": null,
      "outputs": [],
      "id": "O3oQP1rrvc3z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Gcsux3vwZJq"
      },
      "outputs": [],
      "source": [
        "h5_len = len(videos_h5_name)\n",
        "model_PSNR   = np.zeros(h5_len)\n",
        "model_SSIM   = np.zeros(h5_len)\n",
        "bicubic_PSNR = np.zeros(h5_len)\n",
        "bicubic_SSIM = np.zeros(h5_len)\n",
        "model_time   = np.zeros(h5_len)"
      ],
      "id": "2Gcsux3vwZJq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8U3KtNhwawy"
      },
      "outputs": [],
      "source": [
        "out_path = './'\n",
        "if not os.path.exists(out_path):\n",
        "    os.makedirs(out_path)"
      ],
      "id": "J8U3KtNhwawy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA009Ixi2RPw"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import math\n",
        "\n",
        "def psnr(img1, img2):\n",
        "    mse = numpy.mean( (img1 - img2) ** 2 )\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    PIXEL_MAX = 255.0\n",
        "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))"
      ],
      "id": "iA009Ixi2RPw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSlXCgjh2dRH"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "from numpy.lib.stride_tricks import as_strided as ast\n",
        "\n",
        "\"\"\"\n",
        "Hat tip: http://stackoverflow.com/a/5078155/1828289\n",
        "\"\"\"\n",
        "def block_view(A, block=(3, 3)):\n",
        "    \"\"\"Provide a 2D block view to 2D array. No error checking made.\n",
        "    Therefore meaningful (as implemented) only for blocks strictly\n",
        "    compatible with the shape of A.\"\"\"\n",
        "    # simple shape and strides computations may seem at first strange\n",
        "    # unless one is able to recognize the 'tuple additions' involved ;-)\n",
        "    shape = (A.shape[0]// block[0], A.shape[1]// block[1])+ block\n",
        "    strides = (block[0]* A.strides[0], block[1]* A.strides[1])+ A.strides\n",
        "    return ast(A, shape= shape, strides= strides)\n",
        "\n",
        "\n",
        "def ssim(img1, img2, C1=0.01**2, C2=0.03**2):\n",
        "\n",
        "    bimg1 = block_view(img1, (4,4))\n",
        "    bimg2 = block_view(img2, (4,4))\n",
        "    s1  = numpy.sum(bimg1, (-1, -2))\n",
        "    s2  = numpy.sum(bimg2, (-1, -2))\n",
        "    ss  = numpy.sum(bimg1*bimg1, (-1, -2)) + numpy.sum(bimg2*bimg2, (-1, -2))\n",
        "    s12 = numpy.sum(bimg1*bimg2, (-1, -2))\n",
        "\n",
        "    vari = ss - s1*s1 - s2*s2\n",
        "    covar = s12 - s1*s2\n",
        "\n",
        "    ssim_map =  (2*s1*s2 + C1) * (2*covar + C2) / ((s1*s1 + s2*s2 + C1) * (vari + C2))\n",
        "    return numpy.mean(ssim_map)\n",
        "\n",
        "# FIXME there seems to be a problem with this code\n",
        "def ssim_exact(img1, img2, sd=1.5, C1=0.01**2, C2=0.03**2):\n",
        "\n",
        "    mu1 = gaussian_filter(img1, sd)\n",
        "    mu2 = gaussian_filter(img2, sd)\n",
        "    mu1_sq = mu1 * mu1\n",
        "    mu2_sq = mu2 * mu2\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "    sigma1_sq = gaussian_filter(img1 * img1, sd) - mu1_sq\n",
        "    sigma2_sq = gaussian_filter(img2 * img2, sd) - mu2_sq\n",
        "    sigma12 = gaussian_filter(img1 * img2, sd) - mu1_mu2\n",
        "\n",
        "    ssim_num = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2))\n",
        "\n",
        "    ssim_den = ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    ssim_map = ssim_num / ssim_den\n",
        "    return numpy.mean(ssim_map)"
      ],
      "id": "wSlXCgjh2dRH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "1L_fRCrVwhHv",
        "outputId": "435ffffe-eac5-4cfa-ce04-a066b546906e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/14 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-10409b249db2>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimg_LR_Bic_MC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m#print(img_LR_Bic_MC)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mimg_HR_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_LR_Bic_MC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;31m#print('SUPER RESOLUTION!')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m#print(img_HR_net)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-eb432668b157>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mfea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mfea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_last\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHRconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfea\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m#print(out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3929\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3930\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3931\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3932\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3933\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 7.91 GiB (GPU 0; 14.75 GiB total capacity; 9.55 GiB already allocated; 1018.81 MiB free; 12.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "video_idx = 0\n",
        "#   Read h5 file\n",
        "LR_Bic_MC_h5_file = h5py.File('./vsrnet_test_lr', 'r')\n",
        "LR_Bic_MC_h5_data = LR_Bic_MC_h5_file['data']\n",
        "HR_h5_file = h5py.File('./vsrnet_test_hr', 'r')\n",
        "HR_h5_data = HR_h5_file['data']\n",
        "    \n",
        "# load to memory\n",
        "HR_h5_data = HR_h5_data[()]#.value\n",
        "LR_Bic_MC_h5_data = LR_Bic_MC_h5_data[()]#.value\n",
        "    \n",
        "# transpose to correct order\n",
        "HR_h5_data = np.transpose(HR_h5_data, (3, 2, 1, 0))\n",
        "LR_Bic_MC_h5_data = np.transpose(LR_Bic_MC_h5_data, (3, 2, 1, 0))\n",
        "    \n",
        "frame_number = LR_Bic_MC_h5_data.shape[0]\n",
        "\n",
        "IS_REAL_TIME = True\n",
        "\n",
        "video_name = 'scene_40'\n",
        "    \n",
        "if not IS_REAL_TIME:\n",
        "    fps = 30\n",
        "    size = (LR_Bic_MC_h5_data.shape[3], LR_Bic_MC_h5_data.shape[2])\n",
        "    output_name = out_path + video_name.split('.')[0] + '.avi'\n",
        "    videoWriter = cv2.VideoWriter(output_name, cv2.VideoWriter_fourcc('M','J','P','G'), fps, size)\n",
        "#            videoWriter = cv2.VideoWriter(output_name, cv2.VideoWriter_fourcc(*'XVID'), fps, size)\n",
        "        \n",
        "#   Prepare to save PSNR and SSIM of the current video\n",
        "#   Each value corresponding to one test frame\n",
        "model_PSNR_cur   = np.zeros(frame_number)\n",
        "model_SSIM_cur   = np.zeros(frame_number)\n",
        "bicubic_PSNR_cur = np.zeros(frame_number)\n",
        "bicubic_SSIM_cur = np.zeros(frame_number)\n",
        "model_time_cur   = np.zeros(frame_number)\n",
        "    \n",
        "for idx in tqdm(range(0, frame_number)):\n",
        "    img_HR = HR_h5_data[idx, 0, :, :] #2D\n",
        "    img_LR_Bic_MC = LR_Bic_MC_h5_data[idx, :, :, :] #3D 5x1080x1920\n",
        "    \n",
        "    # Reshape to 4D\n",
        "    img_LR_Bic_MC = img_LR_Bic_MC.reshape((1, img_LR_Bic_MC.shape[0], img_LR_Bic_MC.shape[1], img_LR_Bic_MC.shape[2]))\n",
        "    \n",
        "    img_LR_Bic_MC = img_LR_Bic_MC.astype(np.float32)\n",
        "\n",
        "    img_LR_Bic_MC =  torch.from_numpy(img_LR_Bic_MC)\n",
        "                        \n",
        "    if torch.cuda.is_available():\n",
        "        img_LR_Bic_MC = img_LR_Bic_MC.cuda()\n",
        "\n",
        "    start = time.time()\n",
        "    if img_LR_Bic_MC.sum() != 0:\n",
        "        #print(img_LR_Bic_MC)\n",
        "        img_HR_net = model(img_LR_Bic_MC)\n",
        "        #print('SUPER RESOLUTION!')\n",
        "        #print(img_HR_net)\n",
        "        break\n",
        "    else:\n",
        "        img_HR_net = img_LR_Bic_MC[:,2,:,:]\n",
        "        img_HR_net = img_HR_net.reshape((1, 1, img_HR.shape[0], img_HR.shape[1])) # reshape to 1x1x1080x1920\n",
        "        \n",
        "    end = time.time() # measure the computation time\n",
        "    \n",
        "    img_HR_net = img_HR_net.cpu()\n",
        "    img_HR_net = img_HR_net.data[0].numpy()\n",
        "    img_HR_net *= 255.0\n",
        "    img_HR_net = img_HR_net.clip(0, 255)\n",
        "    img_HR_net = img_HR_net.astype(np.uint8)\n",
        "    \n",
        "    img_LR_Bic_MC = img_LR_Bic_MC.cpu()\n",
        "    img_LR_Bic = img_LR_Bic_MC[:, 2, :, :] # center frame\n",
        "    img_LR_Bic = img_LR_Bic.data[0].numpy()\n",
        "    img_LR_Bic *= 255.0\n",
        "    img_LR_Bic = img_LR_Bic.clip(0, 255)\n",
        "    img_LR_Bic = img_LR_Bic.astype(np.uint8)\n",
        "    \n",
        "    img_HR = img_HR.reshape((1, img_HR.shape[0], img_HR.shape[1]))\n",
        "    img_LR_Bic = img_LR_Bic.reshape((1, img_LR_Bic.shape[0], img_LR_Bic.shape[1]))\n",
        "\n",
        "    \n",
        "    model_PSNR_cur[idx]   = psnr((img_HR).reshape(img_HR.shape[1], img_HR.shape[2]).astype(int), (img_HR_net).reshape(img_HR_net.shape[1], img_HR_net.shape[2]).astype(int))\n",
        "    #model_SSIM_cur[idx]   = ssim((img_HR).reshape(img_HR.shape[1], img_HR.shape[2]).astype(int), (img_HR_net).reshape(img_HR_net.shape[1], img_HR_net.shape[2]).astype(int))\n",
        "    bicubic_PSNR_cur[idx] = psnr((img_HR).reshape(img_HR.shape[1], img_HR.shape[2]).astype(int), (img_LR_Bic).reshape(img_LR_Bic.shape[1], img_LR_Bic.shape[2]).astype(int))\n",
        "    bicubic_SSIM_cur[idx] = ssim((img_HR).reshape(img_HR.shape[1], img_HR.shape[2]).astype(int), (img_LR_Bic).reshape(img_LR_Bic.shape[1], img_LR_Bic.shape[2]).astype(int))\n",
        "    model_time_cur[idx]   = (end-start)\n",
        "\n",
        "    # Repeat to 3 channels to save and display\n",
        "    img_HR_net = np.repeat(img_HR_net, 3, axis=0)\n",
        "    img_HR_net = np.transpose(img_HR_net, (1, 2, 0))\n",
        "\n",
        "    if IS_REAL_TIME:\n",
        "        plt.imshow(img_HR_net, cmap = 'gray')\n",
        "        plt.show()\n",
        "\n",
        "#                cv2.imshow('LR Video ', img_LR_Bic)\n",
        "#                cv2.imshow('SR Video ', img_HR_net)\n",
        "#                cv2.waitKey(DELAY_TIME)\n",
        "    else:\n",
        "        # save video\n",
        "        videoWriter.write(img_HR_net)\n",
        "    \n",
        "# Done video writing\n",
        "videoWriter.release()\n",
        "\n",
        "# Save PSNR and SSIM\n",
        "# Exclude PSNR = 100 cases (caused by black frames)\n",
        "cal_flag = (model_PSNR_cur != 100)\n",
        "model_PSNR[video_idx]   = np.mean(model_PSNR_cur[cal_flag])\n",
        "model_SSIM[video_idx]   = np.mean(model_SSIM_cur[cal_flag])\n",
        "bicubic_PSNR[video_idx] = np.mean(bicubic_PSNR_cur[cal_flag])\n",
        "bicubic_SSIM[video_idx] = np.mean(bicubic_SSIM_cur[cal_flag])\n",
        "model_time[video_idx]   = np.mean(model_time_cur[cal_flag])\n",
        "\n",
        "print(\"===> Test on Video Idx: \" + str(video_idx) +\" Complete: Model PSNR: {:.4f} dB, Model SSIM: {:.4f} , Bicubic PSNR:  {:.4f} dB, Bicubic SSIM: {:.4f} , Average time: {:.4f}\"\n",
        "  .format(model_PSNR[video_idx], model_SSIM[video_idx], bicubic_PSNR[video_idx], bicubic_SSIM[video_idx], model_time[video_idx]*1000))\n",
        "video_idx += 1"
      ],
      "id": "1L_fRCrVwhHv"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
